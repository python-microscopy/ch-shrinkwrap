{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a92427e",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PYME.LMVis import VisGUI\n",
    "\n",
    "%gui wx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "133d7954",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "pymevis = VisGUI.ipython_pymevisualize()\n",
    "pipeline = pymevis.pipeline\n",
    "\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87d7fa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This compares ICTM mesh quality as a function of parameters.\n",
    "\"\"\"\n",
    "\n",
    "# Where to save the intermediate files generated \n",
    "save_fp = 'C:\\\\Users\\\\zrc4\\\\Downloads\\\\test_ictm_13'\n",
    "if not os.path.exists(save_fp):\n",
    "    os.mkdir(save_fp)\n",
    "\n",
    "# three way junction generation parameters\n",
    "centroid = np.array([0,0,0])\n",
    "h, r = 500, 50       # capsule length, capsule radius\n",
    "smoothing = r      # ~h/2 creates a three-way junction with a \"sheet\" (but it's puffy like seaweed)\n",
    "# loc precision\n",
    "psf_width = 250.0\n",
    "mean_photon_count = 300.0\n",
    "\n",
    "# octree-based reconstruction parameters\n",
    "cull_inner_surfaces = True\n",
    "n_points_min = 10\n",
    "remesh = True\n",
    "repair = False\n",
    "smooth_curvature = True\n",
    "density = 9e-7\n",
    "\n",
    "# screened poisson reconstruction parameters\n",
    "fulldepth=5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d155a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate three-way junction\n",
    "\"\"\"\n",
    "\n",
    "from ch_shrinkwrap.shape import ThreeWayJunction\n",
    "\n",
    "twj = ThreeWayJunction(h, r, centroid, smoothing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0794f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Generate and save three-way junction ponts\n",
    "\"\"\"\n",
    "import time\n",
    "\n",
    "from ch_shrinkwrap import util\n",
    "\n",
    "cap_points = twj.points(p=0.0001, psf_width=psf_width, mean_photon_count=mean_photon_count, resample=True)\n",
    "cap_sigma = twj._noise\n",
    "\n",
    "no = 0.1\n",
    "scale = 1.2\n",
    "bbox = [np.min(cap_points[:,0]), np.min(cap_points[:,1]), \n",
    "        np.min(cap_points[:,2]), np.max(cap_points[:,0]),\n",
    "        np.max(cap_points[:,1]), np.max(cap_points[:,2])]\n",
    "bbox = [scale*x for x in bbox]\n",
    "xl, yl, zl, xu, yu, zu = bbox\n",
    "xn, yn, zn = xu-xl, yu-yl, zu-zl\n",
    "ln = int(no*len(cap_points)/(1.0-no))\n",
    "noise_points = np.random.rand(ln,3)*(np.array([xn,yn,zn])[None,:]) + (np.array([xl,yl,zl])[None,:])\n",
    "noise_sigma = util.noise(noise_points.shape, model='poisson', psf_width=psf_width, mean_photon_count=mean_photon_count)\n",
    "\n",
    "points = np.vstack([cap_points,noise_points])\n",
    "sigma = np.vstack([cap_sigma,noise_sigma])\n",
    "s = np.sqrt((sigma*sigma).sum(1))\n",
    "\n",
    "points_time = time.strftime('%Y%d%m_%HH%M')\n",
    "points_fn = f\"twj_h{h}_r{r}_smoothing{smoothing}_{points_time}\".replace('.','_')+\".txt\"\n",
    "# points_fn = \"twj_h500_r50_smoothing50_20210911_22H12.txt\"\n",
    "points_fp = os.path.join(save_fp, points_fn)\n",
    "np.savetxt(points_fp, np.vstack([points.T,s]).T, header=\"x y z sigma\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae523fd",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Now we need PYMEVis\n",
    "pymevis.OpenFile(points_fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca3c0f1",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Octree renderer (original mesh based on parameters above)\n",
    "from PYME.LMVis.Extras.extra_layers import gen_octree_from_points\n",
    "from PYME.recipes.surface_fitting import DualMarchingCubes\n",
    "\n",
    "oc_name = gen_octree_from_points(pymevis)\n",
    "surf_name, surf_count = pipeline.new_ds_name('surf', return_count=True)\n",
    "\n",
    "recipe = pipeline.recipe\n",
    "dmc = DualMarchingCubes(recipe, invalidate_parent=False, input=oc_name, output=surf_name,\n",
    "                       threshold_density=density, n_points_min=n_points_min, remesh=remesh,\n",
    "                       repair=repair, cull_inner_surfaces=cull_inner_surfaces, smooth_curvature=smooth_curvature)\n",
    "recipe.add_modules_and_execute([dmc,])\n",
    "\n",
    "octree_fp = points_fp.split('.txt')[0] + '_octree.stl'\n",
    "pipeline.dataSources[dmc.output].to_stl(octree_fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886cbbb9",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "At this point, we will start from the original surface and iterate using\n",
    "different parameters.\n",
    "\"\"\"\n",
    "# Shrinkwrap renderer\n",
    "from ch_shrinkwrap import _membrane_mesh as membrane_mesh\n",
    "\n",
    "max_iters = np.hstack([5, np.logspace(1,2,10).astype(int)])  # integer\n",
    "step_size = np.logspace(0,2,10)                              # float\n",
    "search_k = np.hstack([2,np.arange(0,105,5)[1:]])[:5]         # integer\n",
    "remesh_every = np.array([5,10,20,50,100])                    # integer\n",
    "\n",
    "# max_iters = np.array([10])\n",
    "# remesh_every = np.array([5])\n",
    "# step_size = np.array([12.9])\n",
    "# search_k = np.array([20])\n",
    "\n",
    "failed_count = 0\n",
    "for it in max_iters:\n",
    "    for lam in step_size:\n",
    "        for k in search_k:\n",
    "            for re in remesh_every:\n",
    "                # Copy the mesh over\n",
    "                mesh = membrane_mesh.MembraneMesh(mesh=pipeline.dataSources[dmc.output])\n",
    "\n",
    "                # set params\n",
    "                mesh.max_iter = it\n",
    "                mesh.step_size = lam\n",
    "                mesh.search_k = k\n",
    "                mesh.remesh_frequency = re\n",
    "\n",
    "                start = time.time()\n",
    "                try:\n",
    "                    mesh.shrink_wrap(points, s, method='ictm')\n",
    "                except:\n",
    "                    failed_count += 1\n",
    "                    pass\n",
    "                stop = time.time()\n",
    "                duration = stop-start\n",
    "\n",
    "                wrap_fp = points_fp.split('.txt')[0] + \"_\".join(f\"_iters{it}_remesh{re}_lambda{lam:.1f}_searchk{k}_noise{no:.1f}_ntriangles{mesh.faces.shape[0]}_duration{duration:.1f}_ictm\".split('.')) + \".stl\"\n",
    "                mesh.to_stl(wrap_fp)\n",
    "print(f'# failed: {failed_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ca23d99",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Now calculate SPR.\n",
    "\"\"\"\n",
    "\n",
    "def screened_poisson(points_fp, rowstoskip=1, strformat='X Y Z Reflectance', separator='SPACE',\n",
    "                     colorformat='[0-255]', onerror='skip', k=10, smoothiter=0,\n",
    "                     flipflag=False, viewpos=[0,0,0], depth=8, fulldepth=5,\n",
    "                     cgdepth=0, scale=1.1, samplespernode=1.5, pointweight=4, \n",
    "                     iters=8, confidence=False, preclean=False):\n",
    "    \"\"\"\n",
    "    Run screened poisson reconstruction on a set of points, using meshlab.\n",
    "    \n",
    "    For more information on these parameters, see meshlab.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    points_fp : str\n",
    "        Path to text file containing a point cloud represented as a set of XYZ coordinates\n",
    "    see meshlab\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        File path to STL of reconstruction\n",
    "        \n",
    "    \"\"\"\n",
    "    import pymeshlab as ml\n",
    "\n",
    "    ms = ml.MeshSet()  # create a mesh\n",
    "    ms.load_new_mesh(file_name=points_fp,\n",
    "                     rowtoskip=rowstoskip,\n",
    "                     strformat=strformat,\n",
    "                     separator=separator,\n",
    "                     rgbmode=colorformat,\n",
    "                     onerror=onerror)  # load points\n",
    "    start = time.time()\n",
    "    # compute normals\n",
    "    ms.compute_normals_for_point_sets(k=k,  # number of neighbors\n",
    "                                      smoothiter=smoothiter,\n",
    "                                      flipflag=flipflag,\n",
    "                                      viewpos=viewpos)\n",
    "    # run SPR\n",
    "    ms.surface_reconstruction_screened_poisson(visiblelayer=False,\n",
    "                                               depth=depth,\n",
    "                                               fulldepth=fulldepth,\n",
    "                                               cgdepth=cgdepth,\n",
    "                                               scale=scale,\n",
    "                                               samplespernode=samplespernode,\n",
    "                                               pointweight=pointweight,\n",
    "                                               iters=iters,\n",
    "                                               confidence=confidence,\n",
    "                                               preclean=preclean)\n",
    "    stop = time.time()\n",
    "    duration = stop-start\n",
    "    # save surface\n",
    "    surface_fp = points_fp.split('.txt')[0] + \"_\".join(f\"_searchk{k}_depth{depth}_scale{scale:.1f}_samplespernode{samplespernode:.1f}_pointweight{pointweight:.1f}_iters{iters}_noise{no:.1f}_duration{duration:.1f}_spr\".split('.')) + \".stl\"\n",
    "    ms.save_current_mesh(file_name=surface_fp, unify_vertices=True)\n",
    "    \n",
    "    return surface_fp\n",
    "\n",
    "max_iters = np.arange(7,10)            # integer\n",
    "depth = 2**np.arange(1,4)              # integer\n",
    "search_k = np.arange(5,30,5)           # integer\n",
    "scale=np.linspace(0,1.2,5)             # float\n",
    "samplespernode=np.linspace(13,19,5)    # float\n",
    "pointweight=np.linspace(0,4,5)         # float\n",
    "\n",
    "# max_iters = np.array([8],dtype=int)\n",
    "# depth = np.array([8],dtype=int)\n",
    "# search_k = np.array([10])\n",
    "# scale=np.array([1.1])\n",
    "# samplespernode=np.array([1.5])\n",
    "# pointweight=np.array([4])\n",
    "\n",
    "for it in max_iters:\n",
    "    for k in search_k:\n",
    "        for d in depth:\n",
    "            for sc in scale:\n",
    "                for spn in samplespernode:\n",
    "                    for wt in pointweight:\n",
    "                        spr_fp = screened_poisson(points_fp, k=k, depth=d, fulldepth=fulldepth, \n",
    "                                                  scale=sc, samplespernode=spn, pointweight=wt, iters=it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ebef37",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Now load and analyze the meshes.\n",
    "\"\"\"\n",
    "\n",
    "import re\n",
    "import glob\n",
    "from ch_shrinkwrap import _membrane_mesh as membrane_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4deaae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_points = twj.points(p=0.0001, psf_width=psf_width, mean_photon_count=mean_photon_count, resample=True, noise=None)\n",
    "print(len(test_points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89967ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PYME.experimental.isosurface import distance_to_mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f927811",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "ictm_error, ictm_its, ictm_remesh, ictm_lamb, ictm_pd = [], [], [], [], []\n",
    "ictm_searchk, ictm_noise, ictm_ntris, ictm_runtime = [], [], [], []\n",
    "\n",
    "for fn in glob.glob(save_fp+\"\\\\*ictm.stl\"):\n",
    "    mesh = membrane_mesh.MembraneMesh.from_stl(fn)\n",
    "    ictm_its.append(int(re.search(\"(?<=iters)\\d+\",fn).group(0)))\n",
    "    ictm_remesh.append(int(re.search(\"(?<=remesh)\\d+\",fn).group(0)))\n",
    "    ictm_lamb.append(float(re.search(\"(?<=lambda)\\d+\\_\\d+\",fn).group(0).replace('_','.')))\n",
    "    ictm_searchk.append(int(re.search(\"(?<=searchk)\\d+\",fn).group(0)))\n",
    "    ictm_noise.append(float(re.search(\"(?<=noise)\\d+\\_\\d+\",fn).group(0).replace('_','.')))\n",
    "    ictm_ntris.append(int(re.search(\"(?<=ntriangles)\\d+\",fn).group(0)))\n",
    "    ictm_runtime.append(float(re.search(\"(?<=duration)\\d+\\_\\d+\",fn).group(0).replace('_','.')))\n",
    "    \n",
    "    # Calculate error per face\n",
    "    vecs = mesh._vertices[mesh.faces]['position']\n",
    "    ictm_error.append(twj.sdf(vecs.mean(1).T))\n",
    "    ictm_pd.append(distance_to_mesh(test_points, mesh))\n",
    "    \n",
    "ictm_its, ictm_remesh = np.array(ictm_its), np.array(ictm_remesh)\n",
    "ictm_lamb, ictm_searchk = np.array(ictm_lamb), np.array(ictm_searchk)\n",
    "ictm_noise, ictm_ntris = np.array(ictm_noise), np.array(ictm_ntris)\n",
    "ictm_runtime = np.array(ictm_runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea98b2e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "spr_error, spr_searchk, spr_depth, spr_scale, spr_pd = [], [], [], [], []\n",
    "spr_spn, spr_pointweight, spr_its, spr_noise = [], [], [], []\n",
    "spr_runtime = []\n",
    "\n",
    "fail_count = 0\n",
    "for fn in glob.glob(save_fp+\"\\\\*spr.stl\"):\n",
    "    try:\n",
    "        mesh = membrane_mesh.MembraneMesh.from_stl(fn)\n",
    "        spr_searchk.append(int(re.search(\"(?<=searchk)\\d+\",fn).group(0)))\n",
    "        spr_depth.append(int(re.search(\"(?<=depth)\\d+\",fn).group(0)))\n",
    "        spr_scale.append(float(re.search(\"(?<=scale)\\d+\\_\\d+\",fn).group(0).replace('_','.')))\n",
    "        spr_spn.append(float(re.search(\"(?<=samplespernode)\\d+\\_\\d+\",fn).group(0).replace('_','.')))\n",
    "        spr_pointweight.append(int(re.search(\"(?<=pointweight)\\d+_\\d+\",fn).group(0).replace('_','.')))\n",
    "        spr_its.append(int(re.search(\"(?<=iters)\\d+\",fn).group(0)))\n",
    "        spr_noise.append(float(re.search(\"(?<=noise)\\d+\\_\\d+\",fn).group(0).replace('_','.')))\n",
    "        spr_runtime.append(float(re.search(\"(?<=duration)\\d+\\_\\d+\",fn).group(0).replace('_','.')))\n",
    "\n",
    "        # Calculate error per face\n",
    "        vecs = mesh._vertices[mesh.faces]['position']\n",
    "        spr_error.append(twj.sdf(vecs.mean(1).T))\n",
    "        spr_pd.append(distance_to_mesh(test_points, mesh))\n",
    "    except:\n",
    "        fail_count +=1\n",
    "        \n",
    "print(f'# failed: {fail_count}')\n",
    "    \n",
    "spr_searchk = np.array(spr_searchk)\n",
    "spr_depth, spr_scale = np.array(spr_depth), np.array(spr_scale)\n",
    "spr_spn, spr_pointweight = np.array(spr_spn), np.array(spr_pointweight)\n",
    "spr_its, spr_noise = np.array(spr_its), np.array(spr_noise)\n",
    "spr_runtime = np.array(spr_runtime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "292e1e0c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ictm_mses = []\n",
    "ictm_abs_err = []\n",
    "ictm_pd_err =[]\n",
    "spr_mses = []\n",
    "spr_abs_err = []\n",
    "spr_pd_err = []\n",
    "for i in range(len(ictm_error)):\n",
    "    ictm_mses.append(np.sum(ictm_error[i]**2)/len(ictm_error[i]))\n",
    "    ictm_abs_err.append(np.sum(ictm_error[i]))\n",
    "    ictm_pd_err.append(np.sum(np.abs(ictm_pd[i])))\n",
    "for i in range(len(spr_error)):\n",
    "    spr_mses.append(np.sum(spr_error[i]**2)/len(spr_error[i]))\n",
    "    spr_abs_err.append(np.sum(spr_error[i]))\n",
    "    spr_pd_err.append(np.sum(np.abs(spr_pd[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48041d88",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ebb5df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scatter(ictm_pd_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb6babe6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# idx = np.arange(len(ictm_mses))[~np.isnan(ictm_mses)][np.argmin(np.array(ictm_mses)[~np.isnan(ictm_mses)])]\n",
    "# srt = np.argsort(np.abs(ictm_abs_err))\n",
    "# idx = srt[np.argmax(ictm_ntris[srt]>1000)]\n",
    "# idx = np.argsort(ictm_mses)[114]\n",
    "srt = np.argsort(ictm_mses)\n",
    "cutoff = np.median(np.array(ictm_pd_err)[~np.isnan(ictm_pd_err)])\n",
    "idx = srt[np.argmax(np.array(ictm_pd_err)[srt]<cutoff)]\n",
    "print(\"Best ICTM mesh...\")\n",
    "ictm_fn = points_fp.split('.txt')[0] + \"_\".join(f\"_iters{ictm_its[idx]}_remesh{ictm_remesh[idx]}_lambda{ictm_lamb[idx]:.1f}_searchk{ictm_searchk[idx]}_noise{ictm_noise[idx]:.1f}_ntriangles{ictm_ntris[idx]}_duration{ictm_runtime[idx]:.1f}_ictm\".split('.')) + \".stl\"\n",
    "print(ictm_fn)\n",
    "print(f\"MSE : {ictm_mses[idx]} \",\n",
    "      f\"iters: {ictm_its[idx]}  \", \n",
    "      f\"remesh frequency: {ictm_remesh[idx]} \",\n",
    "      f\"lambda: {ictm_lamb[idx]}  \", \n",
    "      f\"search k: {ictm_searchk[idx]}  \", \n",
    "      f\"noise : {ictm_noise[idx]} \",\n",
    "      f\"# triangles: {ictm_ntris[idx]}\", \n",
    "      f\"duration: {ictm_runtime[idx]}\")\n",
    "\n",
    "# idx = np.argmin(spr_mses)\n",
    "# idx = np.arange(len(spr_mses))[~np.isnan(spr_mses)][np.argmin(np.array(spr_mses)[~np.isnan(spr_mses)])]\n",
    "# idx = np.argmin(np.abs(spr_abs_err))\n",
    "srt = np.argsort(spr_mses)\n",
    "cutoff = np.median(np.array(spr_pd_err)[~np.isnan(spr_pd_err)])\n",
    "idx = srt[np.argmax(np.array(spr_pd_err)[srt]<cutoff)]\n",
    "print(\"Best SPR mesh...\")\n",
    "spr_fn = points_fp.split('.txt')[0] + \"_\".join(f\"_searchk{spr_searchk[idx]}_depth{spr_depth[idx]}_scale{spr_scale[idx]:.1f}_samplespernode{spr_spn[idx]:.1f}_pointweight{spr_pointweight[idx]:.1f}_iters{spr_its[idx]}_noise{spr_noise[idx]:.1f}_duration{spr_runtime[idx]:.1f}_spr\".split('.')) + \".stl\"\n",
    "print(spr_fn)\n",
    "print(f\"MSE : {spr_mses[idx]} \",\n",
    "      f\"search k: {spr_searchk[idx]}  \", \n",
    "      f\"depth: {spr_depth[idx]}  \", \n",
    "      f\"scale: {spr_scale[idx]}  \",\n",
    "      f\"samples per node: {spr_spn[idx]}  \",\n",
    "      f\"pointweight: {spr_pointweight[idx]}  \",      \n",
    "      f\"iters: {spr_its[idx]}  \",  \n",
    "      f\"noise : {spr_noise[idx]} \",\n",
    "      f\"duration: {spr_runtime[idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0de6a8f-5022-425d-a16f-c859e46a1ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def make_scatterplots(x, y, label_x = None, label_y = None, title=None):\n",
    "    assert(len(x) == len(y))\n",
    "    rows, cols = (len(x)+1)//2, 2\n",
    "    fig, axs = plt.subplots(rows, cols)\n",
    "    for i in range(len(x)):\n",
    "        axs[i//2][i%2].scatter(x[i], y[i], s=0.1)\n",
    "        if label_x:\n",
    "            axs[i//2][i%2].set_xlabel(label_x[i])\n",
    "        if label_y:\n",
    "            axs[i//2][i%2].set_ylabel(label_y[i])\n",
    "    if title:\n",
    "        fig.suptitle(title, fontsize=16)\n",
    "        \n",
    "ictm_x = [ictm_its, ictm_remesh, ictm_lamb, ictm_searchk]\n",
    "ictm_y = [ictm_mses]*len(ictm_x)\n",
    "ictm_label_x = ['iterations', 'remesh frequency', 'lambda', 'search k']\n",
    "ictm_label_y = ['MSE']*len(ictm_x)\n",
    "make_scatterplots(ictm_x, ictm_y, ictm_label_x, ictm_label_y, 'ICTM')\n",
    "        \n",
    "spr_x = [spr_searchk, spr_depth, spr_scale, spr_spn, spr_pointweight, spr_its]\n",
    "spr_y = [spr_mses]*len(spr_x)\n",
    "spr_label_x = ['search k', 'depth', 'scale', 'samples per node', 'point weight', 'iterations']\n",
    "spr_label_y = ['MSE']*len(spr_x)\n",
    "make_scatterplots(spr_x, spr_y, spr_label_x, spr_label_y, 'SPR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec52fd1-a226-438d-ab2d-672d35cebe20",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def make_comparative_plot(x, y, list_fixed=[], vals_fixed=None):\n",
    "    \"\"\"\n",
    "    Compare x and y holding values in list_fixed fixed. vals_fixed can\n",
    "    be used to make a subrange of list_fixed.\n",
    "    \"\"\"\n",
    "    assert(len(x) == len(y))\n",
    "    for it in list_fixed:\n",
    "        assert(len(x) == len(it))\n",
    "    unique_fixed = [np.unique(it) for it in list_fixed]\n",
    "    if vals_fixed:\n",
    "        vals_fixed = [it if len(jt) == 0 else jt for it, jt in zip(unique_fixed,vals_fixed)]\n",
    "        unique_fixed = [list(set(it).intersection(jt)) for it, jt in zip(unique_fixed,vals_fixed)]\n",
    "    opts = itertools.product(*unique_fixed)\n",
    "    for opt in opts:\n",
    "        idxs = np.ones(len(x),dtype=bool)\n",
    "        i = 0\n",
    "        for val in opt:\n",
    "            idxs &= (list_fixed[i] == val)\n",
    "            i += 1\n",
    "        xi = x[idxs]\n",
    "        srt = np.argsort(xi)\n",
    "        plt.plot(xi[srt], y[idxs][srt])\n",
    "\n",
    "plt.figure()\n",
    "make_comparative_plot(ictm_its, np.array(ictm_mses), [ictm_lamb, ictm_remesh, ictm_searchk], [[], [50], [10]])\n",
    "plt.legend([f'lambda={lam}' for lam in np.unique(ictm_lamb)])\n",
    "plt.xlabel('# iterations')\n",
    "plt.ylabel('MSE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8a2c38-6d10-4f3a-8b72-fad2737c1d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "make_comparative_plot(spr_pointweight, np.array(spr_mses), [spr_depth, spr_searchk, spr_its, spr_scale, spr_spn], [[4], [], [8], [0.5], [16]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e37affb-6b24-4230-bcf4-58d2fc994222",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.median(np.array(ictm_pd_err)[~np.isnan(ictm_pd_err)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d148568b-08cb-44f0-90b9-0f2cddc86627",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31d4335-6782-40db-8474-242656c0a271",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e799bb-ae9e-40bf-aeaf-6b9c24bd3907",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyme",
   "language": "python",
   "name": "pyme"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
